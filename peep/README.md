# The `peep` Package

## Introduction

The `peep` package is developed to facilitate downloading of data from Google Earth Engine.

The code in this repository is intended to perform two main tasks:

**1. Download and process GEE data**:

* Download satellite data from Google Earth Engine (images and weather data) for a period of time.
    * Downloaded images are divided into 32x32 pixel sub-images, also count metrics are extracted on the amount of images obtained at each pixel and they are summarised at the sub-image level. Both colour (RGB) and pixel counts (COUNT) images are downloaded and stored on the sub-image level.
    * For weather collections the precipitation and temperature "images" are averaged into a single value at each point in the time series.
* The download job is fully specified by a configuration file that can be generated by specifying the details of the data to be downloaded via prompts (satellite to use, coordinates, time period, number of time points, etc.).


This page contains an installation guide, and some usage examples for this package.


## Installation

`peep` requires Python 3.6 or greater. To install, start by creating a fresh `conda` environment.
```
conda create -n gee_pipeline python=3.7
conda activate gee_pipeline
```
Get the source.
```
git clone https://github.com/urbangrammarai/gee_pipeline.git
```
Enter the repository and check out a relevant branch if necessary (the default `master` branch contains the most up to date stable version of the code).
```
cd gee_pipeline
```
Install the package using `pip`.
```
pip install .
```
If you are using Windows and encounter issues during this stage, a solution may be found here: https://github.com/NREL/OpenOA/issues/37. If you plan on making changes to the source code, you can instead run `pip install -e .`.

Before using the Google Earth Engine API, you need to sign up with a Google account. You can read more in [here](https://developers.google.com/earth-engine/guides/python_install), how to open an account and authenticate using [gcloud](https://cloud.google.com/sdk/docs/install).
To authenticate for the first time open python and run
```
ee.Initialize()
```
If you are using `gcloud`, it will initialize automatically.


### Google Earth Engine

[Google Earth Engine](https://earthengine.google.com) (GEE) is a powerful tool for obtaining and analysing satellite imagery. This directory contains some useful scripts for interacting with the Earth Engine API. The earth engine API is installed automatically as part of the `peep` package installation. If you wish to install it separately, you can follow the instructions [here](https://developers.google.com/earth-engine/python_install_manual).

## Downloading data from GEE with ``peep``

### Downloading data from GEE using the CLI

To run a `peep` download job, use
```
peep_run_pipeline --config_file <path to config>
```

The download job is fully specified by a configuration file, which you point to using the `--config_file` argument. A sample config file with relevant functionality for the urban grammar project is found at `peep/configs/config_liverpool_example.py`. You can also optionally specify a string to identify the download job using the `--name` argument.

Note that we use the [BNG convention](https://britishnationalgrid.uk/) for coordinates, i.e. `(eastings,northings)` and we set bounds for regions to download in the convention `(left, bottom, right, top)`.

### Downloading data on a loop from multiple configuration files

You might want to download images from several configuration files in one go. This can be done with the following command:

```
peep_run_pipeline_loop --config_dir configs
```

where `config_dir` is the path to a directory where all the config files you want to run are found. The script runs a loop and
exectues the `peep_run_pipeline` command on each available file found in that path.


#### Generating a download configuration file

To create a configuration file for use in the peep pipeline described above, use the command
```
peep_generate_config
```
this allows the user to specify various characteristics of the data they want to download via prompts. The list in order is as follows:

* `--configs_dir`: The path to the directory containing the config file, with a default option `peep/configs`.

* `--collection_name`: The name of the dataset used in the collection, either Sentinel2, or Landsat 8, 7, 5 or 4.
    *    Sentinel2: [Available from 2015-06-23 at 10m resolution.](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2)
    *    Landsat8: [Available from 2013-04-11 at 30m resolution.](https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LC08_C01_T1)
    *    Landsat7: [Available from 1999-01-01 at 30m resolution.](https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LE07_C01_T1)
    *    Landsat5: [Available from 1984-03-10 to 2013-01-31 at 60m resolution.](https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LT05_C01_T1)
    *    Landsat4: [Available from 1982-07-16 to 1993-12-14 at 60m resolution.](https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LT04_C01_T1)

* `--left`: The left bound of the region to be downloaded (in Easting BNG coordinates) .

* `--bottom`: The bottom bound of the region to be downloaded (in Northing BNG coordinates) .

* `--right`: The right bound of the region to be downloaded (in Easting BNG coordinates) .

* `--top`: The top bound of the region to be downloaded (in Northing BNG coordinates) .

* `--start_date`: The start date in the format ‘YYYY-MM-DD’, the default is ‘2015-01-01’ (or ‘2019-01-01’ for a test config file).

* `--end_date`: The end date in the format ‘YYYY-MM-DD’, the default is today’s date (or ‘2019-03-01’ for a test config file).

* `--time_per_point`: The option to run the image collection either monthly (‘1m’) or weekly (‘1w’), with the default being monthly.

* `--output_dir`: The option to write the output to a specified directory, with the default being the current directory.

For example:
```
 peep_generate_config --configs_dir "peep/configs" --collection_name "Sentinel2" --left 419840 --bottom 0235520 --right 430080 --top 0245760 --start_date "2016-01-01" --end_date "2016-02-01" --time_per_point "1m"
```

This generates a file named `config_Sentinel2_419840_0235520_430080_0245760_2016-01-01_2016-02-01_1m_local.py` along with instructions on how to use this configuration file to download data through the pipeline, in this case the following:

```
peep_run_pipeline --config_file peep/configs/config_Sentinel2_419840_0235520_430080_0245760_2016-01-01_2016-02-01_1m_local.py
```

Individual options can be specified by the user via prompt. The options for this can be found by typing ```peep_generate_config --help```.

#### Generating many configuration files from a geoparquet file

If you want to generate a large number of configuration files from a dataset of geometries you can do this using the command  `peep_generate_config` and
a [geoparquet](https://pypi.org/project/geoparquet/) file (`bounds_file`).

The geoparquet file must contain a column named `geometry`, and each row correspond to an individual geometry (an example of this
file can be found as `images_1024.parquet` on the `testdata` directory).  If provided
the `--bounds_file` flag, the `peep_generate_config` script will read the geoparquet file, loop over its rows creating a config file
for each geometry.

If a column `on_land` is available in the geoparquet file, the script will filter only rows where the column is True.
If not this column is not found, the script will loop over all rows of the data.

Flags such as `start_date`, `end_date`, `time_per_point` must be provided as well, and it will be used for all the config files created.

Flags such as `configs_dir`, `output_dir` are optional, defining to write the output of the config files or downloads to a specified directory
with the default being the current directory.

An example:

```
peep_generate_config --bounds_file testdata/images_1024.parquet  --start_date 2018-04-01 --end_date 2018-10-01 --time_per_point 6m --configs_dir configs --output_dir output_dowloads
```

### More Details on Downloading

During the download job, `peep` will break up your specified date range into a time series defined by the `time_per_point` flag , and download data at each point in the series. Note that by default the images downloaded from GEE will be split up into 32x32 pixel images. Both colour (RGB) and a mosaic with counts of images used in the composite (COUNT) images are downloaded and stored.

### Rerunning partially succeeded jobs

The output location of a download job is datestamped with the time that the job was launched.  The configuration file used will also be copied and datestamped, to aid reproducibility.  For example if you run the job
```
peep_run_pipeline --config_file peep/configs/my_config.py
```
there will be a copy of `my_config.py` saved as `peep/configs/cached_configs/my_config_<datestamp>.py`. This also means that if a job crashes or timeouts partway through, it is possible to rerun, writing to the same output location and skipping parts that are already done by using this cached config file.  However, in order to avoid a second datestamp being appended to the output location, use the ```--from_cache``` argument.  So for the above example, the command to rerun the job filling in any failed/incomplete parts would be:
```
peep_run_pipeline --config_file peep/configs/cached_configs/my_config_<datestamp>.py --from_cache
```

### Using Azure for downloading/processing data

If you have access to Microsoft Azure cloud computing facilities, downloading and processing data can be sped up enormously by using batch computing to run many subjobs in parallel.  This version of the code hasn't been tested on Azure, but legacy code from
[pyveg](https://github.com/alan-turing-institute/monitoring-ecosystem-resilience/tree/master/pyveg) has been kept to facilitate the Azure implementation if needed. See [here](UsingAzure.md) for more details on how Azure is used in [pyveg](https://github.com/alan-turing-institute/monitoring-ecosystem-resilience/tree/master/pyveg).

### Uploading results to the Zenodo open source repository

See [here](UsingZenodo.md) for more details.

# Contributing

We welcome contributions from anyone who is interested in the project. There are lots of ways to contribute, not just writing code. See our [Contributor Guidelines](CONTRIBUTING.md) to learn  more about how you can contribute and how we work together as a community.

# Licence

This project is licensed under the terms of the MIT software license.

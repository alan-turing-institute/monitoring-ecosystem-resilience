{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The *pyveg* package contains some useful functions for interacting with the Python API of Google Earth Engine.\n",
    "\n",
    "However, before we can use GEE, we need to authenticate (assuming we have an account)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines, Sequences, and Modules\n",
    "\n",
    "In pyveg, we have the concept of a \"Pipeline\" for downloading and processing data from GEE.\n",
    "\n",
    "A Pipeline is composed of one or more Sequences, which are in turn composed of Modules.\n",
    "\n",
    "A Module is an class designed for one specific task (e.g. \"download vegetation data from GEE\", or \"calculate network centrality of binary images\"), and they are generally grouped into Sequences such that one Module will work on the output of the previous one.  \n",
    "So our standard Pipeline has:\n",
    "* A vegetation Sequence consisting of VegetationDownloader, VegetationImageProcessor, NetworkCentralityCalculator, and NDVICalculator.   \n",
    "* A weather Sequence consisting of WeatherDownloader, WeatherImageToJSON\n",
    "* A combiner Sequence consisting of a single combiner Module, that takes the outputs of the other two Sequences and produces a final output file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the full pipeline from the command-line\n",
    "\n",
    "For the second part of this notebook will will demonstrate running individual Modules and Sequences, but the majority of users will probably just want to run the full Pipeline for their selected location/collection/date range, so we will cover that first.\n",
    "\n",
    "We have a couple of \"entrypoints\" (i.e. command-line commands) linked to functions in some pyveg scripts to help do this.  \n",
    "* To configure and run a downloading-and-processing pipeline we run the command `pyveg_run_pipeline --config_file <some-config-file>`\n",
    "* To generate the config file in the above command we have the command `pyveg_generate_config`.\n",
    "\n",
    "Both these can accept multiple command-line arguments, and these can be seen with the `--help` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: pyveg_generate_config [-h] [--configs_dir CONFIGS_DIR]\r\n",
      "                             [--collection_name COLLECTION_NAME]\r\n",
      "                             [--output_dir OUTPUT_DIR] [--test_mode]\r\n",
      "                             [--latitude LATITUDE] [--longitude LONGITUDE]\r\n",
      "                             [--country COUNTRY] [--start_date START_DATE]\r\n",
      "                             [--end_date END_DATE]\r\n",
      "                             [--time_per_point TIME_PER_POINT]\r\n",
      "                             [--run_mode RUN_MODE] [--n_threads N_THREADS]\r\n",
      "\r\n",
      "create a config file for running pyveg_pipeline\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --configs_dir CONFIGS_DIR\r\n",
      "                        path to directory containing config files\r\n",
      "  --collection_name COLLECTION_NAME\r\n",
      "                        collection name (e.g. 'Sentinel2')\r\n",
      "  --output_dir OUTPUT_DIR\r\n",
      "                        Directory for local output data\r\n",
      "  --test_mode           Run in test mode, over fewer months and with fewer\r\n",
      "                        sub-images\r\n",
      "  --latitude LATITUDE   latitude in degrees N\r\n",
      "  --longitude LONGITUDE\r\n",
      "                        longitude in degrees E\r\n",
      "  --country COUNTRY     Country of location\r\n",
      "  --start_date START_DATE\r\n",
      "                        start date, format YYYY-MM-DD\r\n",
      "  --end_date END_DATE   end date, format YYYY-MM-DD\r\n",
      "  --time_per_point TIME_PER_POINT\r\n",
      "                        frequency of image, e.g. '1m', '1w'\r\n",
      "  --run_mode RUN_MODE   'local' for running on local machine, 'azure' for\r\n",
      "                        running some time-consuming parts (i.e. vegetation\r\n",
      "                        image processing) on Azure batch\r\n",
      "  --n_threads N_THREADS\r\n",
      "                        How many threads (cores) to parallelize some\r\n",
      "                        processing functions over\r\n"
     ]
    }
   ],
   "source": [
    "!pyveg_generate_config --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `pyveg_generate_config` any parameters it needs that are not provided as command-line arguments will be requested from the user, and the various allowed options will be provided, along with (in most cases) default values that will be used if the user just presses \"enter\".\n",
    "However, this doesn't seem to work so well with Jupyter, so let's just provide all the arguments it needs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitude 11.58 lat_range[0] -90.0 lat_range[1]\r\n",
      "Enter name of country, or press return to use OpenCage country lookup based on coordinates : "
     ]
    }
   ],
   "source": [
    "!pyveg_generate_config --configs_dir ../../pyveg/configs --collection_name Sentinel2 --output_dir ./ --test_mode --latitude 11.58 --longitude 27.94 --country Sudan --start_date 2019-01-01 --end_date 2019-04-01 --time_per_point 1m --run_mode local --n_threads 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "say somethingdasfafa\n"
     ]
    }
   ],
   "source": [
    "x = input(\"say something\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dasfafa'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data - get download URL\n",
    "\n",
    "To specify what we want to download, we create a dictionary.  There is a file *config.py* in pyveg that demonstrates the format (and this is the default one that will be used if you use the command line entrypoint *pyveg_gee_download*).\n",
    "\n",
    "For this example, let's download some Sentinel 2 NDVI data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_dict = {\n",
    "        'collection_name': 'COPERNICUS/S2',\n",
    "        'type': 'vegetation',\n",
    "        'RGB_bands': ('B4','B3','B2'),\n",
    "        'NIR_band': 'B8',\n",
    "        'cloudy_pix_flag': 'CLOUDY_PIXEL_PERCENTAGE',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we also need to specify the coordinates we want to look at (in ***(long,lat)*** format) - let's look at one of our locations in the Sahel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = [28.37,11.12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we need to choose a date range.  If we are looking at vegetation data as in this case, we will take the median of all images available within this date range (after filtering out cloudy ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = [\"2018-06-01\",\"2018-07-31\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to talk to our GEE interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ee_prep_data(collection_dict, coords, date_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GEE has given us a URL from where we can download a zipfile, that will in contain one .tif file per band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and unzipping \n",
    "\n",
    "We need to choose a directory in which to put the unzip-ed .tif files.   Let's just use a temporary directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_filebase = download_and_unzip(urls[0][0], \"/tmp/gee_test_veg\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing RGB, NDVI, and binary images.\n",
    "\n",
    "So we have some .tif files locally (one per band), but they're not that interesting to look at (most image viewing software won't interpret the pixel values in a way that we can see).\n",
    "\n",
    "The first and simplest thing we can do is to create an RGB image from those three bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyveg.src.image_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_img = convert_to_rgb(tif_filebase,collection_dict[\"RGB_bands\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to jump through a few hoops to look at this image in a jupyter notebook, but in a script you could just do rgb_img.save(<filename>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(np.asarray(rgb_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single band image (e.g. NDVI)\n",
    "\n",
    "OK, let's look at the NDVI image.  Again the tif file will only contain one value per pixel - if we want to look at it we need to set r,g,b pixel values to somewhere in the 8-bit colour range to get a greyscale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_img = scale_tif(tif_filebase, \"NDVI\")\n",
    "imshow(np.asarray(ndvi_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image processing and thresholding\n",
    "\n",
    "For our vegetation study, we want to create a binary image from this, where vegetation is in black, and bare soil is white.\n",
    "\n",
    "We have a function in pyveg that does histogram equalization, adaptive thresholding and median filtering on an input image, to give us a binary version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_img = process_and_threshold(ndvi_img)\n",
    "imshow(np.asarray(binary_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting weather data.\n",
    "\n",
    "For our study, we are also interested in the precipitation for this region, and this time range.\n",
    "We can use the ERA5 dataset for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_dict = {\n",
    "        'collection_name': 'ECMWF/ERA5/MONTHLY',\n",
    "        'type': 'weather',\n",
    "        'precipitation_band': ['total_precipitation'],\n",
    "        'temperature_band': ['mean_2m_air_temperature']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, when we ask GEE for the images within our date range, because we set \"type\" to be \"weather\", rather than taking the median image, we will take the sum of the precipitation, and the mean of the temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ee_prep_data(collection_dict, coords, date_range)\n",
    "download_path = \"/tmp/gee_test_weather\"\n",
    "tif_filebase = download_and_unzip(urls[0][0], download_path)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the pyveg *process_satellite_data* module we have some code in a function called *get_weather* that downloads the ERA5 data and puts it into a dictionary.  Let's copy the last few lines of that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {}\n",
    "\n",
    "for file in os.listdir(download_path):\n",
    "    if file.endswith(\".tif\"):\n",
    "        name_variable = (file.split('.'))[1]\n",
    "        variable_array = cv.imread(os.path.join(download_path, file), cv.IMREAD_ANYDEPTH)\n",
    "\n",
    "        metrics_dict[name_variable] = variable_array.mean().astype(np.float64)\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see there was 14cm rain in total in this region in June and July 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting vegetation image into sub-images and analysing connectedness\n",
    "\n",
    "This is quite specific to our analysis, but we also have code to divide the images seen above, which cover about 0.1 degrees in latitude and longitude, into small 50x50 sub-images.  These are then the input to our network centrality calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_images = crop_image_npix(binary_img, 50)\n",
    "imshow(np.asarray(sub_images[300]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then run the network centrality on this, and quantify the connectedness of the vegetation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyveg.src.subgraph_centrality import subgraph_centrality, feature_vector_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = pillow_to_numpy(sub_images[300])\n",
    "feature_vec, _ = subgraph_centrality(img_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature vector is the Euler Characteristic values for each quantile of vegetation-covered pixels, ordered by subgraph centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(feature_vec,'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The single number we are using to quantify the connectedness is \"offset50\" - essentially the slope of the second half of the feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset50 = feature_vector_metrics(feature_vec)[\"offset50\"]\n",
    "offset50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

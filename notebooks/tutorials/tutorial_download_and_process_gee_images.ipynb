{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The *peep* package contains some useful functions for interacting with the Python API of Google Earth Engine to download images, and also code to process these images and prepare them for analysis.\n",
    "\n",
    "In particular, we build composites of the avalaible images during a time period to a single image, that we then divide into 32x32 pixel sub-images, which are saved as .npy files that can be used for analysis.\n",
    "\n",
    "Before we can use GEE, we need to authenticate (assuming we have an account). We recomend use `gcloud` and authenticate before running this notebook.   \n",
    "\n",
    "Another method for authentification is running\n",
    "\n",
    "```\n",
    "ee.Initialize()\n",
    "```\n",
    "and following instructions, however there seems to be a move from GEE to deprecate this method of authentication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines, Sequences, and Modules\n",
    "\n",
    "In `peep`, we have the concept of a \"Pipeline\" for downloading and processing data from GEE.\n",
    "\n",
    "A Pipeline is composed of one or more Sequences, which are in turn composed of Modules.\n",
    "\n",
    "A Module is an class designed for one specific task (e.g. \"download data from GEE\", or \"process tiff file and convert them into RGB images\"), and they are generally grouped into Sequences such that one Module will work on the output of the previous one.  \n",
    "So our standard Pipeline has:\n",
    "* A Download Sequence consisting of ImageDownloader, ImageProcessor.   \n",
    "* A weather Sequence consisting of WeatherDownloader, WeatherImageToJSON\n",
    "\n",
    "For this project we are not dowloading weather, therefore we only will working with the ImageDownloader, and ImageProcessor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the full pipeline from the command-line\n",
    "\n",
    "We have a couple of \"entrypoints\" (i.e. command-line commands) linked to functions in some `peep` scripts to help do this.  \n",
    "* To configure and run a downloading-and-processing pipeline we run the command `peep_run_pipeline --config_file <some-config-file>`\n",
    "* To generate the config file in the above command we have the command `peep_generate_config`.\n",
    "\n",
    "Both these can accept multiple command-line arguments, and these can be seen with the `--help` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!peep_generate_config --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `pyveg_generate_config` any parameters it needs that are not provided as command-line arguments will be requested from the user, and the various allowed options will be provided, along with (in most cases) default values that will be used if the user just presses \"enter\".\n",
    "However, although just running `pyveg_generate_config` with no arguments and then responding to the prompts is probably the easiest way to run it on the command line, this doesn't seem to work so well with Jupyter, so let's just provide all the arguments it needs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!peep_generate_config --configs_dir ../../peep/configs --collection_name Sentinel2 --left 532480 --bottom 174080 --right 542720 --top 184320 --start_date 2016-06-01 --end_date 2016-09-01 --time_per_point 3m --output_dir .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the output that a new config file has been written, and the command we should use to run with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-13 10:15:31,807 [INFO] Sentinel2: setting collection_name to COPERNICUS/S2\n",
      "2022-09-13 10:15:31,807 [INFO] Sentinel2: setting data_type to vegetation\n",
      "2022-09-13 10:15:31,807 [INFO] Sentinel2: setting RGB_bands to ['B4', 'B3', 'B2']\n",
      "2022-09-13 10:15:31,807 [INFO] Sentinel2: setting NIR_band to B8\n",
      "2022-09-13 10:15:31,807 [INFO] Sentinel2: setting mask_cloud to True\n",
      "2022-09-13 10:15:31,807 [INFO] Sentinel2: setting cloudy_pix_frac to 50\n",
      "2022-09-13 10:15:31,807 [INFO] Sentinel2: setting cloudy_pix_flag to CLOUDY_PIXEL_PERCENTAGE\n",
      "2022-09-13 10:15:31,807 [INFO] Sentinel2: setting min_date to 2016-01-01\n",
      "2022-09-13 10:15:31,807 [INFO] Sentinel2: setting max_date to 2022-01-01\n",
      "2022-09-13 10:15:31,808 [INFO] Sentinel2: setting time_per_point to 1m\n",
      "/Users/crangelsmith/opt/anaconda3/envs/geepipeline/lib/python3.7/site-packages/dateparser/date_parser.py:35: PytzUsageWarning: The localize method is no longer necessary, as this time zone supports the fold attribute (PEP 495). For more details on migrating to a PEP 495-compliant implementation, see https://pytz-deprecation-shim.readthedocs.io/en/latest/migration.html\n",
      "  date_obj = stz.localize(date_obj)\n",
      "2022-09-13 10:15:31,839 [INFO] Sentinel2: setting time_per_point to 3m\n",
      "2022-09-13 10:16:31,967 [INFO] Sentinel2_ImageDownloader: Will download to Sentinel2-532480-0174080-542720-0184320__2022-09-13_10-15-31/gee_532480_0174080_542720_0184320_Sentinel2/2016-06-01_2016-09-01/RAW\n",
      "INFO:peep_logger:Sentinel2_ImageDownloader: Will download to Sentinel2-532480-0174080-542720-0184320__2022-09-13_10-15-31/gee_532480_0174080_542720_0184320_Sentinel2/2016-06-01_2016-09-01/RAW\n",
      "2022-09-13 10:16:31,974 [INFO] Sentinel2_ImageDownloader: download succeeded for date range ['2016-06-01', '2016-09-01']\n",
      "INFO:peep_logger:Sentinel2_ImageDownloader: download succeeded for date range ['2016-06-01', '2016-09-01']\n",
      "2022-09-13 10:16:31,974 [INFO] Sentinel2_ImageProcessor: Running local\n",
      "INFO:peep_logger:Sentinel2_ImageProcessor: Running local\n",
      "2022-09-13 10:16:31,975 [INFO] Sentinel2_ImageProcessor processing files in Sentinel2-532480-0174080-542720-0184320__2022-09-13_10-15-31/gee_532480_0174080_542720_0184320_Sentinel2/2016-06-01_2016-09-01/RAW\n",
      "INFO:peep_logger:Sentinel2_ImageProcessor processing files in Sentinel2-532480-0174080-542720-0184320__2022-09-13_10-15-31/gee_532480_0174080_542720_0184320_Sentinel2/2016-06-01_2016-09-01/RAW\n",
      "2022-09-13 10:16:31,975 [INFO] ['download.COUNT.tif', 'download.B4.tif', 'download.B3.tif', 'download.B2.tif']\n",
      "INFO:peep_logger:['download.COUNT.tif', 'download.B4.tif', 'download.B3.tif', 'download.B2.tif']\n",
      "2022-09-13 10:16:32,047 [INFO] Downloaded bounds [532480.0, 174080.0, 542720.0, 184320.0]\n",
      "INFO:peep_logger:Downloaded bounds [532480.0, 174080.0, 542720.0, 184320.0]\n",
      "2022-09-13 10:16:32,047 [INFO] Input bounds [532480, 174080, 542720, 184320]\n",
      "INFO:peep_logger:Input bounds [532480, 174080, 542720, 184320]\n",
      "2022-09-13 10:16:32,047 [INFO] Sentinel2_ImageProcessor: Saving RGB image for 2016-06-01_2016-09-01 532480_174080_542720_184320\n",
      "INFO:peep_logger:Sentinel2_ImageProcessor: Saving RGB image for 2016-06-01_2016-09-01 532480_174080_542720_184320\n",
      "2022-09-13 10:16:37,428 [INFO] Will save image to Sentinel2-532480-0174080-542720-0184320__2022-09-13_10-15-31/gee_532480_0174080_542720_0184320_Sentinel2/2016-06-01_2016-09-01/PROCESSED / 2016-06-01_2016-09-01_532480_174080_542720_184320_RGB.png\n",
      "INFO:peep_logger:Will save image to Sentinel2-532480-0174080-542720-0184320__2022-09-13_10-15-31/gee_532480_0174080_542720_0184320_Sentinel2/2016-06-01_2016-09-01/PROCESSED / 2016-06-01_2016-09-01_532480_174080_542720_184320_RGB.png\n",
      "Saved image 'Sentinel2-532480-0174080-542720-0184320__2022-09-13_10-15-31/gee_532480_0174080_542720_0184320_Sentinel2/2016-06-01_2016-09-01/PROCESSED/2016-06-01_2016-09-01_532480_174080_542720_184320_RGB.png'\n",
      "Saved image 'Sentinel2-532480-0174080-542720-0184320__2022-09-13_10-15-31/gee_532480_0174080_542720_0184320_Sentinel2/2016-06-01_2016-09-01/PROCESSED/2016-06-01_2016-09-01_532480_174080_542720_184320_COUNT.png'\n",
      "2022-09-13 10:16:38,594 [INFO] \n",
      "Sequence Sentinel2\n",
      "INFO:peep_logger:\n",
      "Sequence Sentinel2\n",
      "2022-09-13 10:16:38,594 [INFO] -----------------\n",
      "\n",
      "INFO:peep_logger:-----------------\n",
      "\n",
      "2022-09-13 10:16:38,594 [INFO] Sentinel2_ImageDownloader: Succeeded: 1  Failed: 0   Incomplete: 0\n",
      "INFO:peep_logger:Sentinel2_ImageDownloader: Succeeded: 1  Failed: 0   Incomplete: 0\n",
      "2022-09-13 10:16:38,594 [INFO] Sentinel2_ImageProcessor: Succeeded: 1  Failed: 0   Incomplete: 0\n",
      "INFO:peep_logger:Sentinel2_ImageProcessor: Succeeded: 1  Failed: 0   Incomplete: 0\n",
      "2022-09-13 10:16:38,594 [INFO] \n",
      "\n",
      "INFO:peep_logger:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!peep_run_pipeline --config_file ../../peep/configs/config_Sentinel2_532480_0174080_542720_0184320_2016-06-01_2016-09-01_3m.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So we just:\n",
    "* Downloaded some Sentinel2 images from GEE: particularly bands B2, B3 and B4, as well as a COUNT band that shows how many images were used in the composite at pixel level. \n",
    "* Converted these raw tif images into RGB png (B2, B3 and B4) and a COUNT heatmap png.\n",
    "* Split the RGB png and the COUNT band into 50x50 sub-images.\n",
    "* Save RGB sub-images as arrays in .npy files\n",
    "* Summarise statistics of COUNT sub-images (mean, min, max, etc) in json files.\n",
    "\n",
    "There will now be a directory called \"Sentinel2-532480-0174080-542720-0184320__[date_stamp]\" in your current directory, with a subdirectory called \"gee_532480_0174080_542720_0184320_Sentinel2\". Within this there are directories \"[date-start_date-end]/PROCESSED\" that contain the images and \"[date-start_date-end]/SPLIT\" the sub-images files and \"[date-start_date-end]/RAW\" the original dowloaded bands as tiff files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Running the pieces individually\n",
    "\n",
    "Though the above method is the easiest way to get up-and-running, some users may be interested in running the components of pyveg individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyveg.src.download_modules import VegetationDownloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate this Module:\n",
    "vd = VegetationDownloader(\"Sentinel2_download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of the parameters we need to configure this Module are in the `configs/collections.py` file - there is a large dictionary containing values for e.g. Sentinel 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyveg.configs.collections import data_collections\n",
    "s2_config = data_collections[\"Sentinel2\"]\n",
    "print(s2_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we also need to specify the coordinates we want to look at (in ***(long,lat)*** format) - let's look at one of our locations in the Sahel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = [28.37,11.12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we need to choose a date range.  If we are looking at vegetation data as in this case, we will take the median of all images available within this date range (after filtering out cloudy ones).\n",
    "\n",
    "For the sake of this tutorial, let's just look at a short date range - in fact just a single month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = [\"2018-06-01\",\"2018-07-01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to set an output location to store the files.  We can just use a temporary directory.   The downloaded files will go into a subdirectory of this called \"RAW\", and then into further subdirectories per mid-point of each date sub-range we're looking at.   Here, we are just looking at one month, and the midpoint will be \"2018-06-16\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.name == \"posix\":\n",
    "    TMPDIR = \"/tmp\"\n",
    "else:\n",
    "    TMPDIR = \"%TMP%\"\n",
    "    \n",
    "output_veg_location = os.path.join(TMPDIR,\"gee_veg_download_example\")\n",
    "output_location_type = \"local\" # other alternative currently possible is `azure` for MS Azure cloud, if setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to configure the module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could go through all the key,value pairs in the s2_config dict setting them all\n",
    "# individually, but lets do them all at once\n",
    "vd.set_parameters(s2_config)\n",
    "vd.coords = coords\n",
    "vd.date_range = date_range\n",
    "vd.output_location = output_veg_location\n",
    "vd.output_location_type = output_location_type\n",
    "vd.configure()\n",
    "print(vd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Module is all configured and ready-to-go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should now be some files in the output location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(output_veg_location,\"2018-06-16\",\"RAW\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have one .tif file per band.   \n",
    "\n",
    "The next Module we would normally run in the vegetation Sequence is the VegetationImageProcessor that will take these tif files and produce png images from them.  This includes histogram equalization, adaptive thresholding and median filtering on an input image, to give us binary NDVI images.  It then divides these into 50x50 sub-images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyveg.src.processor_modules import VegetationImageProcessor\n",
    "vip = VegetationImageProcessor(\"Sentinel2_img_processor\")\n",
    "vip.set_parameters(s2_config)\n",
    "vip.coords = coords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only other things we need to set are the `input_location` (which will be the `output_location` from the downloader), and the `output_location` (which we will put as the same as the downloader's one - the results of this will go into different subdirectories of the date-named subdirectories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vip.input_location = vd.output_location\n",
    "vip.output_location = vd.output_location\n",
    "vip.configure()\n",
    "print(vip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vip.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should have created two new subdirectories: \"PROCESSED\" contains the full-size RGB, greyscale, and black-and-white images (the first of these using the RGB bands, and the latter two based on the NDVI band).  \"SPLIT\" contains the 50x50 sub-images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(output_veg_location,\"2018-06-16\",\"PROCESSED\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating network centrality\n",
    "\n",
    "The next step in the standard vegetation sequence is the calculation of \"offset50\", which is related to the \"connectedness\" of the vegetation in the black-and-white NDVI sub-images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyveg.src.processor_modules import NetworkCentralityCalculator\n",
    "ncc = NetworkCentralityCalculator(\"Sentinel2_ncc\")\n",
    "ncc.set_parameters(s2_config)\n",
    "ncc.input_location = vip.output_location\n",
    "ncc.output_location = vip.output_location # same output location again - will create a 'JSON' subdir\n",
    "ncc.configure()\n",
    "print(ncc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One other setting that we might want to change is the number of sub-images per full-size-image for which we do the network centrality calculation.   There are 289 sub-images per full-size-image, and it can be quite time-consuming to process all of them (even though some parallization is implemented - see `n_threads` argument).   We can set this to a smaller number for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncc.n_sub_images = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncc.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now have a json file in the output directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(output_veg_location,\"2018-06-16\",\"JSON\",\"NC\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "j=json.load(open(os.path.join(output_veg_location,\"2018-06-16\",\"JSON\",\"NC\",\"network_centralities.json\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contents of the json file is a list (one entry per sub-image) of dictionaries, and the dictionary keys includ latitude, longitude of the sub-image, as well as \"offset50\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the weather Sequence\n",
    "\n",
    "Here we ran the vegetation-related Modules one-by-one, but we can also combine Modules into Sequences.  As an example, lets do this for the weather downloader Module, and the Module that reads the downloaded images and produces output json files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyveg.src.pyveg_pipeline import Sequence\n",
    "from pyveg.src.download_modules import WeatherDownloader\n",
    "from pyveg.src.processor_modules import WeatherImageToJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era_config = data_collections[\"ERA5\"]\n",
    "era_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default is to download all the monthly weather data since 1986, but for the sake of speed, let's just look at the same small date range as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=Sequence(\"era5_sequence\")\n",
    "s.date_range = date_range\n",
    "s.coords = coords # use the same location as we used above, in the Sahel\n",
    "s.set_config(era_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add Modules to the Sequence, just using the \"+=\" operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s += WeatherDownloader()\n",
    "s += WeatherImageToJSON()\n",
    "s.configure()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been given default values for the \"output_location\", which we might want to override for this example and just use a temporary location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_weather_location = os.path.join(TMPDIR, \"gee_weather_download_example\")\n",
    "s.output_location = output_weather_location\n",
    "# need to reconfigure to propagate this to the Modules\n",
    "s.configure()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're ready to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check we got some output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(output_weather_location, \"2018-06-16\",\"JSON\",\"WEATHER\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "j=json.load(open(os.path.join(output_weather_location, \"2018-06-16\",\"JSON\",\"WEATHER\",\"weather_data.json\")))\n",
    "print(j)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The *pyveg* package contains some useful functions for interacting with the Python API of Google Earth Engine to download images, and also code to process these images and prepare them for analysis.\n",
    "\n",
    "In particular, we want to look at the \"connectedness\" of patterned vegetation.  To do this, we download NDVI (Normalised Difference Vegetation Index) images from GEE, and use some image processing techniques to convert these into binary black-and-white images, that we then divide into 50x50 pixel sub-images, and do some network analysis on them.\n",
    "\n",
    "Before we can use GEE, we need to authenticate (assuming we have an account)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines, Sequences, and Modules\n",
    "\n",
    "In pyveg, we have the concept of a \"Pipeline\" for downloading and processing data from GEE.\n",
    "\n",
    "A Pipeline is composed of one or more Sequences, which are in turn composed of Modules.\n",
    "\n",
    "A Module is an class designed for one specific task (e.g. \"download vegetation data from GEE\", or \"calculate network centrality of binary images\"), and they are generally grouped into Sequences such that one Module will work on the output of the previous one.  \n",
    "So our standard Pipeline has:\n",
    "* A vegetation Sequence consisting of VegetationDownloader, VegetationImageProcessor, NetworkCentralityCalculator, and NDVICalculator.   \n",
    "* A weather Sequence consisting of WeatherDownloader, WeatherImageToJSON\n",
    "* A combiner Sequence consisting of a single combiner Module, that takes the outputs of the other two Sequences and produces a final output file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the full pipeline from the command-line\n",
    "\n",
    "For the second part of this notebook will will demonstrate running individual Modules and Sequences, but the majority of users will probably just want to run the full Pipeline for their selected location/collection/date range, so we will cover that first.\n",
    "\n",
    "We have a couple of \"entrypoints\" (i.e. command-line commands) linked to functions in some pyveg scripts to help do this.  \n",
    "* To configure and run a downloading-and-processing pipeline we run the command `pyveg_run_pipeline --config_file <some-config-file>`\n",
    "* To generate the config file in the above command we have the command `pyveg_generate_config`.\n",
    "\n",
    "Both these can accept multiple command-line arguments, and these can be seen with the `--help` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pyveg_generate_config --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `pyveg_generate_config` any parameters it needs that are not provided as command-line arguments will be requested from the user, and the various allowed options will be provided, along with (in most cases) default values that will be used if the user just presses \"enter\".\n",
    "However, although just running `pyveg_generate_config` with no arguments and then responding to the prompts is probably the easiest way to run it on the command line, this doesn't seem to work so well with Jupyter, so let's just provide all the arguments it needs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pyveg_generate_config --configs_dir ../../pyveg/configs --collection_name Sentinel2 --output_dir ./ --test_mode --latitude 11.58 --longitude 27.94 --country Sudan --start_date 2019-01-01 --end_date 2019-04-01 --time_per_point 1m --run_mode local --n_threads 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the output that a new config file has been written, and the command we should use to run with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pyveg_run_pipeline --config_file ../../pyveg/configs/testconfig_Sentinel2_11.58N_27.94E_Sudan_2019-01-01_2019-04-01_1m_local.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So we just:\n",
    "* Downloaded some Sentinel2 images from GEE\n",
    "* Converted these raw tif images into RGB png, greyscale NDVI png, and black-and-white binarized png images.\n",
    "* Split the above pngs into 50x50 sub-images\n",
    "* Calculated the Network Centrality and total NDVI of each sub-image\n",
    "* Downloaded some ERA5 weather data from GEE\n",
    "* Read off the values of precipitation and temperature from these tifs\n",
    "* Combined the vegetation and weather data into one output file\n",
    "\n",
    "The final output file is called \"results_summary.json\" and contains some metadata describing the configuration, and time-series data for the vegetation and weather."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Running the pieces individually\n",
    "\n",
    "Though the above method is the easiest way to get up-and-running, some users may be interested in running the components of pyveg individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyveg.src.download_modules import VegetationDownloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate this Module:\n",
    "vd = VegetationDownloader(\"Sentinel2_download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of the parameters we need to configure this Module are in the `configs/collections.py` file - there is a large dictionary containing values for e.g. Sentinel 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyveg.configs.collections import data_collections\n",
    "s2_config = data_collections[\"Sentinel2\"]\n",
    "print(s2_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we also need to specify the coordinates we want to look at (in ***(long,lat)*** format) - let's look at one of our locations in the Sahel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = [28.37,11.12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we need to choose a date range.  If we are looking at vegetation data as in this case, we will take the median of all images available within this date range (after filtering out cloudy ones).\n",
    "\n",
    "For the sake of this tutorial, let's just look at a short date range - in fact just a single month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = [\"2018-06-01\",\"2018-07-01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to set an output location to store the files.  We can just use a temporary directory.   The downloaded files will go into a subdirectory of this called \"RAW\", and then into further subdirectories per mid-point of each date sub-range we're looking at.   Here, we are just looking at one month, and the midpoint will be \"2018-06-16\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.name == \"posix\":\n",
    "    TMPDIR = \"/tmp\"\n",
    "else:\n",
    "    TMPDIR = \"%TMP%\"\n",
    "    \n",
    "output_veg_location = os.path.join(TMPDIR,\"gee_veg_download_example\")\n",
    "output_location_type = \"local\" # other alternative currently possible is `azure` for MS Azure cloud, if setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to configure the module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could go through all the key,value pairs in the s2_config dict setting them all\n",
    "# individually, but lets do them all at once\n",
    "vd.set_parameters(s2_config)\n",
    "vd.coords = coords\n",
    "vd.date_range = date_range\n",
    "vd.output_location = output_veg_location\n",
    "vd.output_location_type = output_location_type\n",
    "vd.configure()\n",
    "print(vd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Module is all configured and ready-to-go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should now be some files in the output location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(output_veg_location,\"2018-06-16\",\"RAW\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have one .tif file per band.   \n",
    "\n",
    "The next Module we would normally run in the vegetation Sequence is the VegetationImageProcessor that will take these tif files and produce png images from them.  This includes histogram equalization, adaptive thresholding and median filtering on an input image, to give us binary NDVI images.  It then divides these into 50x50 sub-images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyveg.src.processor_modules import VegetationImageProcessor\n",
    "vip = VegetationImageProcessor(\"Sentinel2_img_processor\")\n",
    "vip.set_parameters(s2_config)\n",
    "vip.coords = coords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only other things we need to set are the `input_location` (which will be the `output_location` from the downloader), and the `output_location` (which we will put as the same as the downloader's one - the results of this will go into different subdirectories of the date-named subdirectories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vip.input_location = vd.output_location\n",
    "vip.output_location = vd.output_location\n",
    "vip.configure()\n",
    "print(vip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vip.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should have created two new subdirectories: \"PROCESSED\" contains the full-size RGB, greyscale, and black-and-white images (the first of these using the RGB bands, and the latter two based on the NDVI band).  \"SPLIT\" contains the 50x50 sub-images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(output_veg_location,\"2018-06-16\",\"PROCESSED\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating network centrality\n",
    "\n",
    "The next step in the standard vegetation sequence is the calculation of \"offset50\", which is related to the \"connectedness\" of the vegetation in the black-and-white NDVI sub-images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyveg.src.processor_modules import NetworkCentralityCalculator\n",
    "ncc = NetworkCentralityCalculator(\"Sentinel2_ncc\")\n",
    "ncc.set_parameters(s2_config)\n",
    "ncc.input_location = vip.output_location\n",
    "ncc.output_location = vip.output_location # same output location again - will create a 'JSON' subdir\n",
    "ncc.configure()\n",
    "print(ncc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One other setting that we might want to change is the number of sub-images per full-size-image for which we do the network centrality calculation.   There are 289 sub-images per full-size-image, and it can be quite time-consuming to process all of them (even though some parallization is implemented - see `n_threads` argument).   We can set this to a smaller number for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncc.n_sub_images = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncc.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now have a json file in the output directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(output_veg_location,\"2018-06-16\",\"JSON\",\"NC\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "j=json.load(open(os.path.join(output_veg_location,\"2018-06-16\",\"JSON\",\"NC\",\"network_centralities.json\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contents of the json file is a list (one entry per sub-image) of dictionaries, and the dictionary keys includ latitude, longitude of the sub-image, as well as \"offset50\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the weather Sequence\n",
    "\n",
    "Here we ran the vegetation-related Modules one-by-one, but we can also combine Modules into Sequences.  As an example, lets do this for the weather downloader Module, and the Module that reads the downloaded images and produces output json files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyveg.src.pyveg_pipeline import Sequence\n",
    "from pyveg.src.download_modules import WeatherDownloader\n",
    "from pyveg.src.processor_modules import WeatherImageToJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era_config = data_collections[\"ERA5\"]\n",
    "era_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default is to download all the monthly weather data since 1986, but for the sake of speed, lets just look at the same small date range as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=Sequence(\"era5_sequence\")\n",
    "s.date_range = date_range\n",
    "s.coords = coords # use the same location as we used above, in the Sahel\n",
    "s.set_config(era_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add Modules to the Sequence, just using the \"+=\" operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s += WeatherDownloader()\n",
    "s += WeatherImageToJSON()\n",
    "s.configure()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been given default values for the \"output_location\", which we might want to override for this example and just use a temporary location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_weather_location = os.path.join(TMPDIR, \"gee_weather_download_example\")\n",
    "s.output_location = output_weather_location\n",
    "# need to reconfigure to propagate this to the Modules\n",
    "s.configure()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're ready to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check we got some output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(output_weather_location, \"2018-06-16\",\"JSON\",\"WEATHER\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "j=json.load(open(os.path.join(output_weather_location, \"2018-06-16\",\"JSON\",\"WEATHER\",\"weather_data.json\")))\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
